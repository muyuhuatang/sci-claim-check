{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train_the_BERT_model_sentence_pair.ipynb","provenance":[],"collapsed_sections":["hBk2pqjCXqDa"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Me3aq3tp404H","outputId":"99a074d0-ba35-4fc7-9d44-fd1282455001","executionInfo":{"status":"ok","timestamp":1648017559542,"user_tz":-480,"elapsed":21245,"user":{"displayName":"fan huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17435630045908849672"}}},"source":["  from google.colab import drive\n","  drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"p9O4eKpI47te","executionInfo":{"status":"ok","timestamp":1648017560086,"user_tz":-480,"elapsed":551,"user":{"displayName":"fan huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17435630045908849672"}}},"source":["  import os\n","  os.chdir(\"/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-5FTAD1dY7m"},"source":["# this is the main referring github repo\n","# my self made few amendments to better fit our project and requirements\n","# !git clone https://github.com/songyouwei/ABSA-PyTorch.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfpQ_u9Ydaau","outputId":"f4bc7203-dc8a-4ddb-ede9-0f5fb3d7e795","executionInfo":{"status":"ok","timestamp":1648017659006,"user_tz":-480,"elapsed":98924,"user":{"displayName":"fan huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17435630045908849672"}}},"source":["# fix the problem: ImportError: cannot import name 'SAVE_STATE_WARNING' from 'torch.optim.lr_scheduler' (/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py)\n","!pip install torch==1.4.0"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.7 kB/s \n","\u001b[?25hInstalling collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.4.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvttsohGd9EI","outputId":"353916f4-c228-4538-af6f-70cff625fb35","executionInfo":{"status":"ok","timestamp":1648017669271,"user_tz":-480,"elapsed":10273,"user":{"displayName":"fan huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17435630045908849672"}}},"source":["!pip install -r requirements.txt"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.5)\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.0)\n","Collecting transformers<4.0.0,>=3.5.1\n","  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.0)\n","Collecting tokenizers==0.9.3\n","  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 42.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (3.6.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 50.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (2019.12.20)\n","Collecting sentencepiece==0.1.91\n","  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 48.4 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (3.17.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (4.63.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 4)) (1.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (3.0.7)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r requirements.txt (line 3)) (7.1.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (3.1.0)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.49 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# generate raw file and print the loaded dataset\n","\n","train_csv_filename = 'datasets/train_update.csv'\n","test_csv_filename = 'datasets/test_phase_1_update.csv'\n","\n","train_raw_filename = 'datasets/train.raw'\n","test_raw_filename = 'datasets/test.raw'\n","\n","result_filename = 'datasets/result.csv'"],"metadata":{"id":"E3WNprbi5Wid","executionInfo":{"status":"ok","timestamp":1648017670491,"user_tz":-480,"elapsed":1226,"user":{"displayName":"fan huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17435630045908849672"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Dataset loding and preprocessing"],"metadata":{"id":"hBk2pqjCXqDa"}},{"cell_type":"code","source":["df_train = pd.read_csv(train_csv_filename)\n","df_train"],"metadata":{"id":"07E3gW7EYplk","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"dcc16f69-171a-40ee-e0b6-1e2a3493e921"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        ID                                              Claim  \\\n","0        0  Antidepressants increase the severity of migra...   \n","1        1  Citrullinated proteins externalized in neutrop...   \n","2        2  Recognition of start codons depends on the tra...   \n","3        3  Ca2+ cycling is a UCP1-dependent thermogenic m...   \n","4        4  Weighed food records (WFR) result in poor comp...   \n","...    ...                                                ...   \n","1174  1174  Birth-weight is negatively associated with bre...   \n","1175  1175  Rhythmic expression of Cry1 translates directl...   \n","1176  1176  Mice lacking Sirt1 in Sf1-expressing neurons h...   \n","1177  1177  Microglia are an innate immune cell type of th...   \n","1178  1178  There is no increased risk of hypospadias with...   \n","\n","                                               Evidence  Label  \n","0     Tricyclics were also more likely to reduce the...      2  \n","1     These observations implicate accelerated NETos...      1  \n","2     IF3 and tRNA undergo large conformational chan...      1  \n","3     Conversely, enhanced Ca2+ cycling by activatio...      2  \n","4     The Hippo pathway controls organ size and tiss...      0  \n","...                                                 ...    ...  \n","1174  The relative risk estimate for breast cancer c...      2  \n","1175  Cry1 expression was elevated during the night-...      1  \n","1176  Also, mutant mice have increased susceptibilit...      1  \n","1177  Here, we develop a conceptual framework for fu...      2  \n","1178  The adverse effect is less severe in sons, alt...      2  \n","\n","[1179 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-de5bae22-6dc3-47cc-a47e-86abc3cc2317\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Claim</th>\n","      <th>Evidence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Antidepressants increase the severity of migra...</td>\n","      <td>Tricyclics were also more likely to reduce the...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Citrullinated proteins externalized in neutrop...</td>\n","      <td>These observations implicate accelerated NETos...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Recognition of start codons depends on the tra...</td>\n","      <td>IF3 and tRNA undergo large conformational chan...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Ca2+ cycling is a UCP1-dependent thermogenic m...</td>\n","      <td>Conversely, enhanced Ca2+ cycling by activatio...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Weighed food records (WFR) result in poor comp...</td>\n","      <td>The Hippo pathway controls organ size and tiss...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1174</th>\n","      <td>1174</td>\n","      <td>Birth-weight is negatively associated with bre...</td>\n","      <td>The relative risk estimate for breast cancer c...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1175</th>\n","      <td>1175</td>\n","      <td>Rhythmic expression of Cry1 translates directl...</td>\n","      <td>Cry1 expression was elevated during the night-...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1176</th>\n","      <td>1176</td>\n","      <td>Mice lacking Sirt1 in Sf1-expressing neurons h...</td>\n","      <td>Also, mutant mice have increased susceptibilit...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1177</th>\n","      <td>1177</td>\n","      <td>Microglia are an innate immune cell type of th...</td>\n","      <td>Here, we develop a conceptual framework for fu...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1178</th>\n","      <td>1178</td>\n","      <td>There is no increased risk of hypospadias with...</td>\n","      <td>The adverse effect is less severe in sons, alt...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1179 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de5bae22-6dc3-47cc-a47e-86abc3cc2317')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-de5bae22-6dc3-47cc-a47e-86abc3cc2317 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-de5bae22-6dc3-47cc-a47e-86abc3cc2317');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df_train['Label'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ju0TobTZbxGn","outputId":"73c160c9-3b81-4f7f-a157-4dcf729c2c0b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    602\n","2    316\n","0    261\n","Name: Label, dtype: int64"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["df_test = pd.read_csv(test_csv_filename)\n","df_test"],"metadata":{"id":"wc4yW3BoZWkr","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"be9952e3-0108-4f45-8943-a99043bd563d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      ID                                              Claim  \\\n","0      0  Beta-band coherence is diminished for visible ...   \n","1      1  Physical activity level is associated with the...   \n","2      2  Autologous transplantation of mesenchymal stem...   \n","3      3  RAD52 is involved in break-induced DNA replica...   \n","4      4  Human embryonic stem cells give rise to cell t...   \n","..   ...                                                ...   \n","145  145  Origin gross domestic product(GDP) is positive...   \n","146  146  Surgical treatment is not superior to non-surg...   \n","147  147  Cancer-associated fibroblasts (CAFs) interact ...   \n","148  148  Persistor cells are one reason for incomplete ...   \n","149  149  Normal expression of RUNX1 causes tumorsupress...   \n","\n","                                              Evidence  \n","0    This result suggests that traces of a heavy me...  \n","1    The best diagnostic performance is obtained wh...  \n","2    After 6 months, 4 of 53 patients (7.5%) in the...  \n","3    At CFSs, this fragility is associated with a d...  \n","4    Embryonic stem cells have the ability to remai...  \n","..                                                 ...  \n","145  However, mature size DNA products accumulated ...  \n","146  RESULTS There was no significant mean treatmen...  \n","147  Further, we demonstrated that LXR is poly(ADP-...  \n","148  CONTEXT The epidemic of heart failure has yet ...  \n","149  Notably, a network structure analysis of this ...  \n","\n","[150 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-94a91498-d221-43d9-9344-f5ef72bb9cb6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Claim</th>\n","      <th>Evidence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Beta-band coherence is diminished for visible ...</td>\n","      <td>This result suggests that traces of a heavy me...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Physical activity level is associated with the...</td>\n","      <td>The best diagnostic performance is obtained wh...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Autologous transplantation of mesenchymal stem...</td>\n","      <td>After 6 months, 4 of 53 patients (7.5%) in the...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>RAD52 is involved in break-induced DNA replica...</td>\n","      <td>At CFSs, this fragility is associated with a d...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Human embryonic stem cells give rise to cell t...</td>\n","      <td>Embryonic stem cells have the ability to remai...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>145</td>\n","      <td>Origin gross domestic product(GDP) is positive...</td>\n","      <td>However, mature size DNA products accumulated ...</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>146</td>\n","      <td>Surgical treatment is not superior to non-surg...</td>\n","      <td>RESULTS There was no significant mean treatmen...</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>147</td>\n","      <td>Cancer-associated fibroblasts (CAFs) interact ...</td>\n","      <td>Further, we demonstrated that LXR is poly(ADP-...</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>148</td>\n","      <td>Persistor cells are one reason for incomplete ...</td>\n","      <td>CONTEXT The epidemic of heart failure has yet ...</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>149</td>\n","      <td>Normal expression of RUNX1 causes tumorsupress...</td>\n","      <td>Notably, a network structure analysis of this ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94a91498-d221-43d9-9344-f5ef72bb9cb6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94a91498-d221-43d9-9344-f5ef72bb9cb6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94a91498-d221-43d9-9344-f5ef72bb9cb6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["df_test['Label'] = 0\n","df_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"0pmcDbM5Zr4a","outputId":"ae0c55ef-ecda-4b6e-e9d4-91e312d2a832"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      ID                                              Claim  \\\n","0      0  Beta-band coherence is diminished for visible ...   \n","1      1  Physical activity level is associated with the...   \n","2      2  Autologous transplantation of mesenchymal stem...   \n","3      3  RAD52 is involved in break-induced DNA replica...   \n","4      4  Human embryonic stem cells give rise to cell t...   \n","..   ...                                                ...   \n","145  145  Origin gross domestic product(GDP) is positive...   \n","146  146  Surgical treatment is not superior to non-surg...   \n","147  147  Cancer-associated fibroblasts (CAFs) interact ...   \n","148  148  Persistor cells are one reason for incomplete ...   \n","149  149  Normal expression of RUNX1 causes tumorsupress...   \n","\n","                                              Evidence  Label  \n","0    This result suggests that traces of a heavy me...      0  \n","1    The best diagnostic performance is obtained wh...      0  \n","2    After 6 months, 4 of 53 patients (7.5%) in the...      0  \n","3    At CFSs, this fragility is associated with a d...      0  \n","4    Embryonic stem cells have the ability to remai...      0  \n","..                                                 ...    ...  \n","145  However, mature size DNA products accumulated ...      0  \n","146  RESULTS There was no significant mean treatmen...      0  \n","147  Further, we demonstrated that LXR is poly(ADP-...      0  \n","148  CONTEXT The epidemic of heart failure has yet ...      0  \n","149  Notably, a network structure analysis of this ...      0  \n","\n","[150 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-9bdf6814-bffa-41e8-b8a2-e292d3b2d07f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>Claim</th>\n","      <th>Evidence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Beta-band coherence is diminished for visible ...</td>\n","      <td>This result suggests that traces of a heavy me...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Physical activity level is associated with the...</td>\n","      <td>The best diagnostic performance is obtained wh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Autologous transplantation of mesenchymal stem...</td>\n","      <td>After 6 months, 4 of 53 patients (7.5%) in the...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>RAD52 is involved in break-induced DNA replica...</td>\n","      <td>At CFSs, this fragility is associated with a d...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Human embryonic stem cells give rise to cell t...</td>\n","      <td>Embryonic stem cells have the ability to remai...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>145</td>\n","      <td>Origin gross domestic product(GDP) is positive...</td>\n","      <td>However, mature size DNA products accumulated ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>146</td>\n","      <td>Surgical treatment is not superior to non-surg...</td>\n","      <td>RESULTS There was no significant mean treatmen...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>147</td>\n","      <td>Cancer-associated fibroblasts (CAFs) interact ...</td>\n","      <td>Further, we demonstrated that LXR is poly(ADP-...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>148</td>\n","      <td>Persistor cells are one reason for incomplete ...</td>\n","      <td>CONTEXT The epidemic of heart failure has yet ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>149</td>\n","      <td>Normal expression of RUNX1 causes tumorsupress...</td>\n","      <td>Notably, a network structure analysis of this ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bdf6814-bffa-41e8-b8a2-e292d3b2d07f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9bdf6814-bffa-41e8-b8a2-e292d3b2d07f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9bdf6814-bffa-41e8-b8a2-e292d3b2d07f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# generate raw file for training set\n","df = pd.DataFrame(df_train, columns=['Claim', 'Evidence', 'Label'])\n","# preprocess the textual column remove \\n\n","df['Claim'] = df['Claim'].replace('\\n', ' ', regex = True)\n","df['Evidence'] = df['Evidence'].replace('\\n', ' ', regex = True)\n","df = df.dropna()\n","print(df)\n","\n","# use the csv file to generate the raw file that used for the model running\n","# save .raw file\n","df.to_csv(train_raw_filename, sep='\\n', index = False, header = False)\n","print('the generate for ['+train_raw_filename+'] files is completed')"],"metadata":{"id":"aM-bR5qNYpLe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c8434bf-6a15-44d9-d7a7-d210a36a2586"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                  Claim  \\\n","0     Antidepressants increase the severity of migra...   \n","1     Citrullinated proteins externalized in neutrop...   \n","2     Recognition of start codons depends on the tra...   \n","3     Ca2+ cycling is a UCP1-dependent thermogenic m...   \n","4     Weighed food records (WFR) result in poor comp...   \n","...                                                 ...   \n","1174  Birth-weight is negatively associated with bre...   \n","1175  Rhythmic expression of Cry1 translates directl...   \n","1176  Mice lacking Sirt1 in Sf1-expressing neurons h...   \n","1177  Microglia are an innate immune cell type of th...   \n","1178  There is no increased risk of hypospadias with...   \n","\n","                                               Evidence  Label  \n","0     Tricyclics were also more likely to reduce the...      2  \n","1     These observations implicate accelerated NETos...      1  \n","2     IF3 and tRNA undergo large conformational chan...      1  \n","3     Conversely, enhanced Ca2+ cycling by activatio...      2  \n","4     The Hippo pathway controls organ size and tiss...      0  \n","...                                                 ...    ...  \n","1174  The relative risk estimate for breast cancer c...      2  \n","1175  Cry1 expression was elevated during the night-...      1  \n","1176  Also, mutant mice have increased susceptibilit...      1  \n","1177  Here, we develop a conceptual framework for fu...      2  \n","1178  The adverse effect is less severe in sons, alt...      2  \n","\n","[1179 rows x 3 columns]\n","the generate for [datasets/train.raw] files is completed\n"]}]},{"cell_type":"code","source":["# generate raw file for testing set\n","df = pd.DataFrame(df_test, columns=['Claim', 'Evidence', 'Label'])\n","# preprocess the textual column remove \\n\n","df['Claim'] = df['Claim'].replace('\\n', ' ', regex = True)\n","df['Evidence'] = df['Evidence'].replace('\\n', ' ', regex = True)\n","df = df.dropna()\n","print(df)\n","\n","# use the csv file to generate the raw file that used for the model running\n","# save .raw file\n","df.to_csv(test_raw_filename, sep='\\n', index = False, header = False)\n","print('the generate for ['+test_raw_filename+'] files is completed')"],"metadata":{"id":"_h070NvLbyIA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5204485-9743-4561-beb8-acdf12fc8766"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                 Claim  \\\n","0    Beta-band coherence is diminished for visible ...   \n","1    Physical activity level is associated with the...   \n","2    Autologous transplantation of mesenchymal stem...   \n","3    RAD52 is involved in break-induced DNA replica...   \n","4    Human embryonic stem cells give rise to cell t...   \n","..                                                 ...   \n","145  Origin gross domestic product(GDP) is positive...   \n","146  Surgical treatment is not superior to non-surg...   \n","147  Cancer-associated fibroblasts (CAFs) interact ...   \n","148  Persistor cells are one reason for incomplete ...   \n","149  Normal expression of RUNX1 causes tumorsupress...   \n","\n","                                              Evidence  Label  \n","0    This result suggests that traces of a heavy me...      0  \n","1    The best diagnostic performance is obtained wh...      0  \n","2    After 6 months, 4 of 53 patients (7.5%) in the...      0  \n","3    At CFSs, this fragility is associated with a d...      0  \n","4    Embryonic stem cells have the ability to remai...      0  \n","..                                                 ...    ...  \n","145  However, mature size DNA products accumulated ...      0  \n","146  RESULTS There was no significant mean treatmen...      0  \n","147  Further, we demonstrated that LXR is poly(ADP-...      0  \n","148  CONTEXT The epidemic of heart failure has yet ...      0  \n","149  Notably, a network structure analysis of this ...      0  \n","\n","[150 rows x 3 columns]\n","the generate for [datasets/test.raw] files is completed\n"]}]},{"cell_type":"markdown","metadata":{"id":"D9E2lJo7ejdn"},"source":["## Run the codes"]},{"cell_type":"code","metadata":{"id":"k40y1uJBelNx"},"source":["!python dependency_graph.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python train.py --model_name lstm --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuPgvqtHuLUF","outputId":"f6e38b09-ad26-4781-dd0c-721003265794","executionInfo":{"status":"ok","timestamp":1648017698049,"user_tz":-480,"elapsed":27561,"user":{"displayName":"fan huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17435630045908849672"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["loading tokenizer: phase-1_tokenizer.dat\n","loading embedding_matrix: 300_phase-1_embedding_matrix.dat\n","cuda memory allocated: 11683328\n","> n_trainable_params: 723303, n_nontrainable_params: 2197200\n","> training arguments:\n",">>> model_name: lstm\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fc5b2540290>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.1\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lstm.LSTM'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['text_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.2119, acc: 0.2125\n","loss: 1.2024, acc: 0.2156\n","loss: 1.1933, acc: 0.2188\n","loss: 1.1822, acc: 0.2203\n","loss: 1.1748, acc: 0.2175\n","loss: 1.1661, acc: 0.2281\n","> val_acc: 0.2479, val_f1: 0.2043\n",">> saved: state_dict/lstm_phase-1_val_acc_0.2479\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 1.1241, acc: 0.1875\n","loss: 1.1083, acc: 0.2740\n","loss: 1.0977, acc: 0.3451\n","loss: 1.0910, acc: 0.3845\n","loss: 1.0877, acc: 0.3997\n","loss: 1.0846, acc: 0.4151\n","loss: 1.0832, acc: 0.4147\n","> val_acc: 0.4786, val_f1: 0.2350\n",">> saved: state_dict/lstm_phase-1_val_acc_0.4786\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 1.0566, acc: 0.4896\n","loss: 1.0449, acc: 0.5156\n","loss: 1.0401, acc: 0.5144\n","loss: 1.0358, acc: 0.5295\n","loss: 1.0393, acc: 0.5082\n","loss: 1.0389, acc: 0.5056\n","loss: 1.0390, acc: 0.5028\n","> val_acc: 0.5043, val_f1: 0.2248\n",">> saved: state_dict/lstm_phase-1_val_acc_0.5043\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 1.0093, acc: 0.5417\n","loss: 1.0141, acc: 0.5230\n","loss: 1.0307, acc: 0.4892\n","loss: 1.0370, acc: 0.4840\n","loss: 1.0350, acc: 0.4911\n","loss: 1.0254, acc: 0.5021\n","> val_acc: 0.5043, val_f1: 0.2248\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 1.0517, acc: 0.4062\n","loss: 1.0545, acc: 0.4427\n","loss: 1.0312, acc: 0.4801\n","loss: 1.0403, acc: 0.4727\n","loss: 1.0271, acc: 0.4866\n","loss: 1.0214, acc: 0.4988\n","loss: 1.0102, acc: 0.5111\n","> val_acc: 0.5128, val_f1: 0.2273\n",">> saved: state_dict/lstm_phase-1_val_acc_0.5128\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.9593, acc: 0.5500\n","loss: 1.0068, acc: 0.5000\n","loss: 0.9992, acc: 0.5075\n","loss: 0.9947, acc: 0.5179\n","loss: 0.9984, acc: 0.5208\n","loss: 0.9988, acc: 0.5170\n","loss: 1.0089, acc: 0.5029\n","> val_acc: 0.5128, val_f1: 0.2273\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.9842, acc: 0.5156\n","loss: 0.9859, acc: 0.5312\n","loss: 0.9929, acc: 0.5179\n","loss: 0.9934, acc: 0.5181\n","loss: 0.9985, acc: 0.5169\n","loss: 1.0006, acc: 0.5108\n","> val_acc: 0.5128, val_f1: 0.2273\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 1.0837, acc: 0.3125\n","loss: 1.0029, acc: 0.5000\n","loss: 0.9973, acc: 0.5060\n","loss: 0.9864, acc: 0.5262\n","loss: 0.9990, acc: 0.5168\n","loss: 0.9982, acc: 0.5086\n","loss: 0.9957, acc: 0.5123\n","> val_acc: 0.5128, val_f1: 0.2273\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 1.0164, acc: 0.4844\n","loss: 0.9844, acc: 0.5179\n","loss: 0.9820, acc: 0.5260\n","loss: 0.9743, acc: 0.5331\n","loss: 0.9919, acc: 0.5085\n","loss: 0.9837, acc: 0.5231\n","loss: 0.9895, acc: 0.5156\n","> val_acc: 0.5128, val_f1: 0.2273\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 1.0124, acc: 0.4911\n","loss: 0.9908, acc: 0.5000\n","loss: 0.9814, acc: 0.5139\n","loss: 0.9767, acc: 0.5338\n","loss: 0.9766, acc: 0.5319\n","loss: 0.9798, acc: 0.5252\n","loss: 0.9839, acc: 0.5188\n","> val_acc: 0.5043, val_f1: 0.2248\n",">> early stop.\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","<class 'torch.Tensor'>\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1])\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n"]}]},{"cell_type":"code","source":["!python train.py --model_name atae_lstm --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OzmHCMrYgILm","outputId":"67406712-e104-4a3c-fd9c-487f2267e47a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading tokenizer: phase-1_tokenizer.dat\n","loading embedding_matrix: 300_phase-1_embedding_matrix.dat\n","cuda memory allocated: 19546624\n","> n_trainable_params: 2525703, n_nontrainable_params: 2197200\n","> training arguments:\n",">>> model_name: atae_lstm\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f4e340d63b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.1\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.atae_lstm.ATAE_LSTM'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.1460, acc: 0.2375\n","loss: 1.1434, acc: 0.2188\n","loss: 1.1365, acc: 0.2271\n","loss: 1.1294, acc: 0.2375\n","loss: 1.1250, acc: 0.2412\n","loss: 1.1206, acc: 0.2531\n","> val_acc: 0.3932, val_f1: 0.2716\n",">> saved: state_dict/atae_lstm_phase-1_val_acc_0.3932\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 1.0869, acc: 0.4167\n","loss: 1.0766, acc: 0.4567\n","loss: 1.0793, acc: 0.4375\n","loss: 1.0740, acc: 0.4545\n","loss: 1.0760, acc: 0.4506\n","loss: 1.0738, acc: 0.4611\n","loss: 1.0681, acc: 0.4732\n","> val_acc: 0.5385, val_f1: 0.2333\n",">> saved: state_dict/atae_lstm_phase-1_val_acc_0.5385\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 1.0272, acc: 0.5417\n","loss: 1.0304, acc: 0.5273\n","loss: 1.0354, acc: 0.5072\n","loss: 1.0398, acc: 0.5052\n","loss: 1.0432, acc: 0.4973\n","loss: 1.0410, acc: 0.5033\n","loss: 1.0363, acc: 0.5047\n","> val_acc: 0.5470, val_f1: 0.2357\n",">> saved: state_dict/atae_lstm_phase-1_val_acc_0.547\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.9824, acc: 0.5486\n","loss: 1.0051, acc: 0.5329\n","loss: 1.0261, acc: 0.5086\n","loss: 1.0191, acc: 0.5176\n","loss: 1.0268, acc: 0.5013\n","loss: 1.0267, acc: 0.5000\n","> val_acc: 0.5470, val_f1: 0.2357\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 1.0920, acc: 0.4688\n","loss: 1.0004, acc: 0.5417\n","loss: 1.0229, acc: 0.5000\n","loss: 1.0200, acc: 0.5000\n","loss: 1.0168, acc: 0.5045\n","loss: 1.0168, acc: 0.5048\n","loss: 1.0102, acc: 0.5131\n","> val_acc: 0.5470, val_f1: 0.2357\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 1.0202, acc: 0.4750\n","loss: 1.0063, acc: 0.5083\n","loss: 0.9970, acc: 0.5250\n","loss: 0.9964, acc: 0.5196\n","loss: 0.9972, acc: 0.5208\n","loss: 1.0032, acc: 0.5136\n","loss: 1.0041, acc: 0.5067\n","> val_acc: 0.5470, val_f1: 0.2357\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 1.0088, acc: 0.5078\n","loss: 0.9971, acc: 0.5278\n","loss: 1.0080, acc: 0.5000\n","loss: 0.9958, acc: 0.5049\n","loss: 0.9978, acc: 0.5039\n","loss: 0.9935, acc: 0.5140\n","> val_acc: 0.5470, val_f1: 0.2357\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.9031, acc: 0.6250\n","loss: 1.0110, acc: 0.4943\n","loss: 1.0098, acc: 0.4940\n","loss: 1.0050, acc: 0.4940\n","loss: 0.9964, acc: 0.5000\n","loss: 0.9926, acc: 0.5061\n","loss: 0.9933, acc: 0.5041\n","> val_acc: 0.5385, val_f1: 0.2333\n",">> early stop.\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","<class 'torch.Tensor'>\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1])\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n"]}]},{"cell_type":"code","source":["!python train.py --model_name ian --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8buZbz84P3t","outputId":"6f26b3ea-2919-449f-c689-62c8c258c461"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading tokenizer: phase-1_tokenizer.dat\n","loading embedding_matrix: 300_phase-1_embedding_matrix.dat\n","cuda memory allocated: 17469440\n","> n_trainable_params: 2168403, n_nontrainable_params: 2197200\n","> training arguments:\n",">>> model_name: ian\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f16d450d3b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.1\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.ian.IAN'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['text_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","loss: 1.1088, acc: 0.2812\n","loss: 1.0928, acc: 0.2938\n","loss: 1.0855, acc: 0.2875\n","loss: 1.0756, acc: 0.3219\n","loss: 1.0703, acc: 0.3625\n","loss: 1.0639, acc: 0.3958\n","> val_acc: 0.4444, val_f1: 0.2051\n",">> saved: state_dict/ian_phase-1_val_acc_0.4444\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","loss: 1.0499, acc: 0.5000\n","loss: 1.0330, acc: 0.5240\n","loss: 1.0238, acc: 0.5299\n","loss: 1.0311, acc: 0.5152\n","loss: 1.0245, acc: 0.5233\n","loss: 1.0231, acc: 0.5212\n","loss: 1.0242, acc: 0.5198\n","> val_acc: 0.4444, val_f1: 0.2051\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","loss: 1.0146, acc: 0.5312\n","loss: 0.9973, acc: 0.5508\n","loss: 1.0072, acc: 0.5361\n","loss: 1.0242, acc: 0.5087\n","loss: 1.0272, acc: 0.5041\n","loss: 1.0194, acc: 0.5156\n","loss: 1.0174, acc: 0.5189\n","> val_acc: 0.4444, val_f1: 0.2051\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","loss: 1.0215, acc: 0.5069\n","loss: 1.0382, acc: 0.4803\n","loss: 1.0226, acc: 0.5000\n","loss: 1.0222, acc: 0.5000\n","loss: 1.0205, acc: 0.5051\n","loss: 1.0164, acc: 0.5117\n","> val_acc: 0.4444, val_f1: 0.2051\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","loss: 1.1033, acc: 0.4062\n","loss: 1.0300, acc: 0.5052\n","loss: 1.0120, acc: 0.5170\n","loss: 1.0128, acc: 0.5215\n","loss: 1.0062, acc: 0.5298\n","loss: 1.0076, acc: 0.5252\n","loss: 1.0100, acc: 0.5202\n","> val_acc: 0.4444, val_f1: 0.2051\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","loss: 0.8900, acc: 0.6625\n","loss: 0.9392, acc: 0.5958\n","loss: 0.9560, acc: 0.5775\n","loss: 0.9825, acc: 0.5411\n","loss: 0.9932, acc: 0.5319\n","loss: 0.9969, acc: 0.5261\n","loss: 1.0042, acc: 0.5154\n","> val_acc: 0.4444, val_f1: 0.2051\n",">> early stop.\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  aspect_len = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/ian.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  text_raw_len = torch.tensor(text_raw_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","<class 'torch.Tensor'>\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1])\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n"]}]},{"cell_type":"code","source":["!python train.py --model_name bert_spc --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PLjlxq4B5hLu","outputId":"298dea43-67a6-4269-cd14-cbebeace602c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: 100% 232k/232k [00:00<00:00, 641kB/s]\n","Downloading: 100% 570/570 [00:00<00:00, 573kB/s]\n","Downloading: 100% 440M/440M [00:07<00:00, 62.9MB/s]\n","cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f419c3783b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.1\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.1228, acc: 0.5437\n","loss: 1.0996, acc: 0.5312\n","loss: 1.0952, acc: 0.4854\n","loss: 1.0916, acc: 0.4656\n","loss: 1.0799, acc: 0.4525\n","loss: 1.0718, acc: 0.4552\n","> val_acc: 0.6154, val_f1: 0.5024\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6154\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 0.9997, acc: 0.4792\n","loss: 0.9662, acc: 0.5144\n","loss: 0.9419, acc: 0.5353\n","loss: 0.9264, acc: 0.5436\n","loss: 0.9129, acc: 0.5683\n","loss: 0.9055, acc: 0.5708\n","loss: 0.8906, acc: 0.5813\n","> val_acc: 0.6068, val_f1: 0.5881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.6639, acc: 0.7083\n","loss: 0.7049, acc: 0.6836\n","loss: 0.7138, acc: 0.6683\n","loss: 0.7191, acc: 0.6684\n","loss: 0.7175, acc: 0.6603\n","loss: 0.6908, acc: 0.6797\n","loss: 0.6842, acc: 0.6866\n","> val_acc: 0.6752, val_f1: 0.6590\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.5032, acc: 0.8056\n","loss: 0.4969, acc: 0.8059\n","loss: 0.4930, acc: 0.8017\n","loss: 0.5020, acc: 0.7997\n","loss: 0.5025, acc: 0.8023\n","loss: 0.4861, acc: 0.8104\n","> val_acc: 0.6581, val_f1: 0.6408\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.3673, acc: 0.8750\n","loss: 0.3357, acc: 0.8646\n","loss: 0.3420, acc: 0.8494\n","loss: 0.3611, acc: 0.8457\n","loss: 0.3344, acc: 0.8586\n","loss: 0.3340, acc: 0.8606\n","loss: 0.3301, acc: 0.8639\n","> val_acc: 0.7094, val_f1: 0.7102\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7094\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.2053, acc: 0.9000\n","loss: 0.2086, acc: 0.9083\n","loss: 0.2097, acc: 0.9150\n","loss: 0.1928, acc: 0.9268\n","loss: 0.1887, acc: 0.9319\n","loss: 0.2305, acc: 0.9193\n","loss: 0.2271, acc: 0.9202\n","> val_acc: 0.7949, val_f1: 0.7961\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7949\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.1210, acc: 0.9375\n","loss: 0.1463, acc: 0.9375\n","loss: 0.1455, acc: 0.9442\n","loss: 0.1501, acc: 0.9375\n","loss: 0.1682, acc: 0.9323\n","loss: 0.1716, acc: 0.9321\n","> val_acc: 0.7949, val_f1: 0.7977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.0304, acc: 1.0000\n","loss: 0.0618, acc: 0.9830\n","loss: 0.0753, acc: 0.9762\n","loss: 0.0841, acc: 0.9738\n","loss: 0.0960, acc: 0.9680\n","loss: 0.0938, acc: 0.9669\n","loss: 0.0900, acc: 0.9682\n","> val_acc: 0.8889, val_f1: 0.8834\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8889\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.0542, acc: 0.9844\n","loss: 0.0488, acc: 0.9866\n","loss: 0.0535, acc: 0.9844\n","loss: 0.0673, acc: 0.9761\n","loss: 0.0686, acc: 0.9773\n","loss: 0.0751, acc: 0.9734\n","loss: 0.0754, acc: 0.9756\n","> val_acc: 0.8889, val_f1: 0.8833\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.0139, acc: 1.0000\n","loss: 0.0613, acc: 0.9743\n","loss: 0.0469, acc: 0.9838\n","loss: 0.0476, acc: 0.9814\n","loss: 0.0571, acc: 0.9787\n","loss: 0.0573, acc: 0.9792\n","loss: 0.0631, acc: 0.9765\n","> val_acc: 0.9060, val_f1: 0.9021\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.906\n","<class 'torch.Tensor'>\n","tensor([0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 1, 2, 1,\n","        1, 2, 1, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 2,\n","        0, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0,\n","        0, 1, 1, 1, 1, 2, 0, 1, 0, 0, 1, 0, 1, 2, 1, 0, 1, 1, 2, 0, 1, 2, 0, 0,\n","        2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 2, 2, 0, 1,\n","        2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0,\n","        1, 0, 2, 1, 0, 1])\n","0\n","0\n","1\n","1\n","1\n","0\n","0\n","2\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","2\n","1\n","2\n","0\n","0\n","1\n","1\n","2\n","1\n","1\n","2\n","1\n","1\n","1\n","0\n","0\n","1\n","1\n","2\n","1\n","0\n","1\n","1\n","2\n","0\n","0\n","1\n","0\n","0\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","2\n","1\n","1\n","0\n","2\n","0\n","1\n","2\n","1\n","1\n","0\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","2\n","0\n","1\n","0\n","0\n","1\n","0\n","1\n","2\n","1\n","0\n","1\n","1\n","2\n","0\n","1\n","2\n","0\n","0\n","2\n","2\n","1\n","1\n","2\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","1\n","2\n","2\n","0\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","0\n","1\n","2\n","1\n","0\n","0\n","2\n","1\n","1\n","0\n","1\n","1\n","0\n","1\n","0\n","1\n","0\n","2\n","1\n","0\n","1\n"]}]},{"cell_type":"code","source":["!python train.py --model_name aen_bert --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7dxCenb5npL","outputId":"64789d7d-5eba-4be3-fa44-0c2307817242"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda memory allocated: 452894208\n","> n_trainable_params: 112937661, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: aen_bert\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fc66d7013b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.1\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.aen.AEN_BERT'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['text_bert_indices', 'aspect_bert_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 1.5308, acc: 0.3563\n","loss: 1.3434, acc: 0.3750\n","loss: 1.2351, acc: 0.4333\n","loss: 1.1698, acc: 0.4484\n","loss: 1.1291, acc: 0.4725\n","loss: 1.0977, acc: 0.4896\n","> val_acc: 0.4615, val_f1: 0.4655\n",">> saved: state_dict/aen_bert_phase-1_val_acc_0.4615\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9219, acc: 0.5833\n","loss: 0.9320, acc: 0.5913\n","loss: 0.9132, acc: 0.5870\n","loss: 0.8774, acc: 0.5985\n","loss: 0.8722, acc: 0.5974\n","loss: 0.8668, acc: 0.5979\n","loss: 0.8690, acc: 0.6022\n","> val_acc: 0.5299, val_f1: 0.4563\n",">> saved: state_dict/aen_bert_phase-1_val_acc_0.5299\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.7442, acc: 0.6771\n","loss: 0.7153, acc: 0.7109\n","loss: 0.6943, acc: 0.7212\n","loss: 0.6959, acc: 0.7066\n","loss: 0.6707, acc: 0.7255\n","loss: 0.6885, acc: 0.7087\n","loss: 0.6973, acc: 0.6979\n","> val_acc: 0.6667, val_f1: 0.6112\n",">> saved: state_dict/aen_bert_phase-1_val_acc_0.6667\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.5521, acc: 0.7847\n","loss: 0.5180, acc: 0.7993\n","loss: 0.5034, acc: 0.7974\n","loss: 0.4838, acc: 0.8109\n","loss: 0.4724, acc: 0.8214\n","loss: 0.4822, acc: 0.8136\n","> val_acc: 0.7265, val_f1: 0.7140\n",">> saved: state_dict/aen_bert_phase-1_val_acc_0.7265\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.4391, acc: 0.8438\n","loss: 0.3258, acc: 0.9010\n","loss: 0.3306, acc: 0.8892\n","loss: 0.3044, acc: 0.8867\n","loss: 0.3280, acc: 0.8750\n","loss: 0.3284, acc: 0.8726\n","loss: 0.3312, acc: 0.8730\n","> val_acc: 0.8034, val_f1: 0.7812\n",">> saved: state_dict/aen_bert_phase-1_val_acc_0.8034\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.2266, acc: 0.9500\n","loss: 0.2059, acc: 0.9250\n","loss: 0.2005, acc: 0.9350\n","loss: 0.1864, acc: 0.9411\n","loss: 0.2029, acc: 0.9361\n","loss: 0.1975, acc: 0.9386\n","loss: 0.1958, acc: 0.9356\n","> val_acc: 0.7949, val_f1: 0.7427\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.1497, acc: 0.9297\n","loss: 0.1594, acc: 0.9410\n","loss: 0.1682, acc: 0.9308\n","loss: 0.1675, acc: 0.9326\n","loss: 0.1571, acc: 0.9375\n","loss: 0.1553, acc: 0.9407\n","> val_acc: 0.7949, val_f1: 0.7629\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.1609, acc: 0.9375\n","loss: 0.1355, acc: 0.9432\n","loss: 0.1044, acc: 0.9583\n","loss: 0.1011, acc: 0.9657\n","loss: 0.1290, acc: 0.9543\n","loss: 0.1122, acc: 0.9620\n","loss: 0.1189, acc: 0.9621\n","> val_acc: 0.8291, val_f1: 0.7698\n",">> saved: state_dict/aen_bert_phase-1_val_acc_0.8291\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.0810, acc: 0.9844\n","loss: 0.0988, acc: 0.9643\n","loss: 0.0911, acc: 0.9609\n","loss: 0.0904, acc: 0.9651\n","loss: 0.0906, acc: 0.9645\n","loss: 0.1038, acc: 0.9630\n","loss: 0.1031, acc: 0.9629\n","> val_acc: 0.8291, val_f1: 0.8009\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.0295, acc: 1.0000\n","loss: 0.0451, acc: 0.9926\n","loss: 0.0488, acc: 0.9907\n","loss: 0.0459, acc: 0.9916\n","loss: 0.0451, acc: 0.9907\n","loss: 0.0471, acc: 0.9868\n","loss: 0.0569, acc: 0.9831\n","> val_acc: 0.8120, val_f1: 0.7658\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","<class 'torch.Tensor'>\n","tensor([0, 0, 1, 0, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 2, 0, 1, 2, 1, 2, 1,\n","        1, 2, 1, 1, 2, 0, 2, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2, 2, 0, 2, 0, 1, 2, 2,\n","        0, 1, 0, 1, 1, 0, 1, 0, 2, 2, 1, 1, 1, 1, 0, 2, 2, 1, 0, 0, 1, 0, 1, 1,\n","        1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 1, 1, 2, 1, 2, 0, 0, 2, 0, 2,\n","        2, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 0, 1,\n","        2, 1, 1, 1, 0, 1, 2, 1, 0, 2, 1, 2, 1, 2, 1, 2, 2, 1, 0, 2, 0, 0, 1, 0,\n","        1, 0, 2, 1, 2, 1])\n","0\n","0\n","1\n","0\n","2\n","1\n","2\n","2\n","2\n","1\n","2\n","1\n","0\n","2\n","1\n","1\n","1\n","2\n","0\n","1\n","2\n","1\n","2\n","1\n","1\n","2\n","1\n","1\n","2\n","0\n","2\n","2\n","0\n","2\n","0\n","2\n","0\n","1\n","1\n","1\n","2\n","2\n","0\n","2\n","0\n","1\n","2\n","2\n","0\n","1\n","0\n","1\n","1\n","0\n","1\n","0\n","2\n","2\n","1\n","1\n","1\n","1\n","0\n","2\n","2\n","1\n","0\n","0\n","1\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","0\n","0\n","0\n","0\n","2\n","0\n","1\n","2\n","1\n","1\n","2\n","1\n","2\n","0\n","0\n","2\n","0\n","2\n","2\n","2\n","1\n","1\n","2\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","2\n","2\n","1\n","0\n","1\n","2\n","1\n","1\n","1\n","0\n","1\n","2\n","1\n","0\n","2\n","1\n","2\n","1\n","2\n","1\n","2\n","2\n","1\n","0\n","2\n","0\n","0\n","1\n","0\n","1\n","0\n","2\n","1\n","2\n","1\n"]}]},{"cell_type":"code","source":["!python train.py --model_name lcf_bert --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fLQa0uKe60e6","outputId":"3526f79b-ac63-4de7-c805-d87c8d9bad3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda memory allocated: 455608832\n","> n_trainable_params: 113617923, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: lcf_bert\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f6ae234c3b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.1\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.lcf_bert.LCF_BERT'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices', 'text_bert_indices', 'aspect_bert_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.2102, acc: 0.4188\n","loss: 1.1050, acc: 0.4469\n","loss: 1.0583, acc: 0.4813\n","loss: 1.0365, acc: 0.4859\n","loss: 1.0222, acc: 0.5125\n","loss: 1.0104, acc: 0.5073\n","> val_acc: 0.6068, val_f1: 0.4802\n",">> saved: state_dict/lcf_bert_phase-1_val_acc_0.6068\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 0.8299, acc: 0.5625\n","loss: 0.8556, acc: 0.5529\n","loss: 0.7854, acc: 0.6196\n","loss: 0.7776, acc: 0.6288\n","loss: 0.7837, acc: 0.6308\n","loss: 0.7674, acc: 0.6439\n","loss: 0.7520, acc: 0.6508\n","> val_acc: 0.6923, val_f1: 0.5658\n",">> saved: state_dict/lcf_bert_phase-1_val_acc_0.6923\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.6222, acc: 0.6875\n","loss: 0.5596, acc: 0.7656\n","loss: 0.5932, acc: 0.7188\n","loss: 0.5802, acc: 0.7274\n","loss: 0.5869, acc: 0.7201\n","loss: 0.5716, acc: 0.7310\n","loss: 0.5663, acc: 0.7225\n","> val_acc: 0.6838, val_f1: 0.6130\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.3901, acc: 0.8333\n","loss: 0.3822, acc: 0.8355\n","loss: 0.3742, acc: 0.8297\n","loss: 0.4058, acc: 0.8237\n","loss: 0.4229, acc: 0.8176\n","loss: 0.4222, acc: 0.8189\n","> val_acc: 0.7436, val_f1: 0.7521\n",">> saved: state_dict/lcf_bert_phase-1_val_acc_0.7436\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.4721, acc: 0.8125\n","loss: 0.3289, acc: 0.8698\n","loss: 0.2759, acc: 0.8807\n","loss: 0.2785, acc: 0.8770\n","loss: 0.2706, acc: 0.8869\n","loss: 0.2643, acc: 0.8906\n","loss: 0.2693, acc: 0.8871\n","> val_acc: 0.8291, val_f1: 0.8174\n",">> saved: state_dict/lcf_bert_phase-1_val_acc_0.8291\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.1998, acc: 0.9250\n","loss: 0.1586, acc: 0.9417\n","loss: 0.1659, acc: 0.9350\n","loss: 0.1595, acc: 0.9339\n","loss: 0.1588, acc: 0.9375\n","loss: 0.1750, acc: 0.9318\n","loss: 0.1774, acc: 0.9298\n","> val_acc: 0.8803, val_f1: 0.8741\n",">> saved: state_dict/lcf_bert_phase-1_val_acc_0.8803\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.1371, acc: 0.9531\n","loss: 0.1310, acc: 0.9514\n","loss: 0.1191, acc: 0.9576\n","loss: 0.1075, acc: 0.9655\n","loss: 0.0992, acc: 0.9674\n","loss: 0.1041, acc: 0.9623\n","> val_acc: 0.8632, val_f1: 0.8475\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.2229, acc: 0.8125\n","loss: 0.1223, acc: 0.9545\n","loss: 0.0970, acc: 0.9643\n","loss: 0.0788, acc: 0.9758\n","loss: 0.0750, acc: 0.9771\n","loss: 0.0754, acc: 0.9755\n","loss: 0.0857, acc: 0.9703\n","> val_acc: 0.8547, val_f1: 0.8390\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.1193, acc: 0.9688\n","loss: 0.0941, acc: 0.9732\n","loss: 0.0854, acc: 0.9740\n","loss: 0.0902, acc: 0.9743\n","loss: 0.0831, acc: 0.9744\n","loss: 0.0747, acc: 0.9792\n","loss: 0.0737, acc: 0.9785\n","> val_acc: 0.8632, val_f1: 0.8462\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.0441, acc: 1.0000\n","loss: 0.0642, acc: 0.9890\n","loss: 0.0522, acc: 0.9884\n","loss: 0.0438, acc: 0.9899\n","loss: 0.0405, acc: 0.9907\n","loss: 0.0481, acc: 0.9857\n","loss: 0.0502, acc: 0.9840\n","> val_acc: 0.8718, val_f1: 0.8642\n","<class 'torch.Tensor'>\n","tensor([0, 0, 0, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 1, 2, 1,\n","        1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 1, 0, 2, 1, 1, 1, 2,\n","        0, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 0,\n","        0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 2, 1, 0, 1, 1, 2, 0, 1, 2, 0, 0,\n","        2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 2, 0, 1,\n","        2, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0,\n","        1, 0, 2, 1, 0, 1])\n","0\n","0\n","0\n","1\n","1\n","0\n","0\n","2\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","1\n","2\n","0\n","0\n","1\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","2\n","1\n","0\n","1\n","1\n","2\n","0\n","0\n","1\n","0\n","2\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","2\n","1\n","1\n","0\n","1\n","0\n","1\n","2\n","1\n","1\n","0\n","0\n","0\n","1\n","0\n","0\n","2\n","1\n","1\n","1\n","1\n","0\n","0\n","0\n","0\n","1\n","0\n","1\n","2\n","1\n","0\n","1\n","1\n","2\n","0\n","1\n","2\n","0\n","0\n","2\n","2\n","1\n","1\n","2\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","2\n","1\n","2\n","0\n","1\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","1\n","0\n","1\n","2\n","1\n","0\n","0\n","2\n","1\n","1\n","0\n","1\n","1\n","0\n","1\n","0\n","1\n","0\n","2\n","1\n","0\n","1\n"]}]},{"cell_type":"code","source":["!python train.py --model_name memnet --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_g17F71F7dvq","outputId":"767f9994-5299-4d91-a668-daf77f311d42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading tokenizer: phase-1_tokenizer.dat\n","loading embedding_matrix: 300_phase-1_embedding_matrix.dat\n","cuda memory allocated: 10244096\n","> n_trainable_params: 362703, n_nontrainable_params: 2197200\n","> training arguments:\n",">>> model_name: memnet\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7efbeca103b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.1\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.memnet.MemNet'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['context_indices', 'aspect_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 1.0591, acc: 0.4875\n","loss: 1.0327, acc: 0.5031\n","loss: 1.0335, acc: 0.4875\n","loss: 1.0294, acc: 0.4922\n","loss: 1.0172, acc: 0.5025\n","loss: 1.0260, acc: 0.4917\n","> val_acc: 0.5726, val_f1: 0.2687\n",">> saved: state_dict/memnet_phase-1_val_acc_0.5726\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9555, acc: 0.5833\n","loss: 0.9870, acc: 0.5240\n","loss: 0.9955, acc: 0.5190\n","loss: 0.9869, acc: 0.5284\n","loss: 0.9938, acc: 0.5160\n","loss: 0.9976, acc: 0.5047\n","loss: 0.9931, acc: 0.5119\n","> val_acc: 0.5726, val_f1: 0.3222\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9841, acc: 0.5312\n","loss: 0.9804, acc: 0.5273\n","loss: 0.9854, acc: 0.5096\n","loss: 0.9749, acc: 0.5139\n","loss: 0.9673, acc: 0.5204\n","loss: 0.9667, acc: 0.5257\n","loss: 0.9742, acc: 0.5170\n","> val_acc: 0.5556, val_f1: 0.3030\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9227, acc: 0.5625\n","loss: 0.9428, acc: 0.5329\n","loss: 0.9520, acc: 0.5194\n","loss: 0.9554, acc: 0.5160\n","loss: 0.9613, acc: 0.5089\n","loss: 0.9569, acc: 0.5201\n","> val_acc: 0.5556, val_f1: 0.3720\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9946, acc: 0.5000\n","loss: 0.9541, acc: 0.5260\n","loss: 0.9721, acc: 0.5057\n","loss: 0.9592, acc: 0.5215\n","loss: 0.9442, acc: 0.5327\n","loss: 0.9419, acc: 0.5337\n","loss: 0.9473, acc: 0.5242\n","> val_acc: 0.5470, val_f1: 0.3847\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.8972, acc: 0.5500\n","loss: 0.9193, acc: 0.5458\n","loss: 0.9282, acc: 0.5300\n","loss: 0.9315, acc: 0.5232\n","loss: 0.9447, acc: 0.5111\n","loss: 0.9381, acc: 0.5261\n","loss: 0.9321, acc: 0.5288\n","> val_acc: 0.5812, val_f1: 0.3129\n",">> saved: state_dict/memnet_phase-1_val_acc_0.5812\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9337, acc: 0.5234\n","loss: 0.9599, acc: 0.5104\n","loss: 0.9439, acc: 0.5246\n","loss: 0.9359, acc: 0.5395\n","loss: 0.9385, acc: 0.5378\n","loss: 0.9317, acc: 0.5420\n","> val_acc: 0.5641, val_f1: 0.4372\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9884, acc: 0.5000\n","loss: 0.9578, acc: 0.5057\n","loss: 0.9207, acc: 0.5595\n","loss: 0.9166, acc: 0.5685\n","loss: 0.9132, acc: 0.5640\n","loss: 0.9158, acc: 0.5490\n","loss: 0.9231, acc: 0.5451\n","> val_acc: 0.5726, val_f1: 0.4414\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9292, acc: 0.5781\n","loss: 0.8901, acc: 0.5714\n","loss: 0.8918, acc: 0.5677\n","loss: 0.9049, acc: 0.5607\n","loss: 0.9025, acc: 0.5483\n","loss: 0.8990, acc: 0.5498\n","loss: 0.9040, acc: 0.5459\n","> val_acc: 0.5897, val_f1: 0.4947\n",">> saved: state_dict/memnet_phase-1_val_acc_0.5897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","loss: 0.9090, acc: 0.5804\n","loss: 0.8723, acc: 0.6103\n","loss: 0.8958, acc: 0.5856\n","loss: 0.8879, acc: 0.5861\n","loss: 0.8971, acc: 0.5798\n","loss: 0.8942, acc: 0.5779\n","loss: 0.8960, acc: 0.5697\n","> val_acc: 0.5470, val_f1: 0.4346\n","/content/drive/MyDrive/SMU/Courses/ML/Traditional-Models-SPC/models/memnet.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  nonzeros_aspect = torch.tensor(aspect_len, dtype=torch.float).to(self.opt.device)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","<class 'torch.Tensor'>\n","tensor([2, 0, 1, 0, 1, 0, 1, 1, 2, 2, 1, 2, 0, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1,\n","        1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n","        0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 2, 0, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 0,\n","        0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n","        2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n","        1, 0, 0, 1, 1, 1])\n","2\n","0\n","1\n","0\n","1\n","0\n","1\n","1\n","2\n","2\n","1\n","2\n","0\n","2\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","1\n","1\n","0\n","1\n","0\n","1\n","1\n","0\n","2\n","0\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","2\n","1\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","2\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","1\n","1\n","0\n","0\n","1\n","2\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","0\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","0\n","1\n","0\n","0\n","1\n","1\n","1\n"]}]},{"cell_type":"markdown","source":["## More about BERT"],"metadata":{"id":"GzmE5QvS_z-d"}},{"cell_type":"code","source":["!python train.py --model_name bert_spc --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"id":"84XNKp0s_36v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### val ratios"],"metadata":{"id":"NDtNmN3a__sO"}},{"cell_type":"code","source":["!python train.py --model_name bert_spc --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.15"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnQ9RJaQADUx","outputId":"692365d6-7575-4eec-bf90-3b5c39c1da85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fb6872733b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.15\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.2435, acc: 0.4500\n","loss: 1.2322, acc: 0.4281\n","loss: 1.1688, acc: 0.4354\n","loss: 1.1172, acc: 0.4641\n","loss: 1.0786, acc: 0.4863\n","loss: 1.0435, acc: 0.5115\n","> val_acc: 0.5398, val_f1: 0.5028\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.5398\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 0.9151, acc: 0.5000\n","loss: 0.8746, acc: 0.5919\n","loss: 0.8704, acc: 0.5972\n","loss: 0.8399, acc: 0.6115\n","loss: 0.8384, acc: 0.6051\n","loss: 0.8192, acc: 0.6118\n","> val_acc: 0.6250, val_f1: 0.4934\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.625\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.7904, acc: 0.5781\n","loss: 0.6767, acc: 0.7054\n","loss: 0.6462, acc: 0.7188\n","loss: 0.6333, acc: 0.7188\n","loss: 0.6162, acc: 0.7216\n","loss: 0.6343, acc: 0.7118\n","> val_acc: 0.6420, val_f1: 0.6624\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.642\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.4154, acc: 0.8125\n","loss: 0.4987, acc: 0.7784\n","loss: 0.4880, acc: 0.7708\n","loss: 0.5037, acc: 0.7681\n","loss: 0.4867, acc: 0.7835\n","loss: 0.4768, acc: 0.7868\n","loss: 0.4562, acc: 0.7961\n","> val_acc: 0.6761, val_f1: 0.6958\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6761\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.3401, acc: 0.8516\n","loss: 0.2894, acc: 0.8993\n","loss: 0.2762, acc: 0.9062\n","loss: 0.2956, acc: 0.8947\n","loss: 0.3268, acc: 0.8763\n","loss: 0.3286, acc: 0.8761\n","> val_acc: 0.7727, val_f1: 0.7621\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7727\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.3182, acc: 0.8875\n","loss: 0.2268, acc: 0.9333\n","loss: 0.2228, acc: 0.9300\n","loss: 0.2208, acc: 0.9286\n","loss: 0.2200, acc: 0.9250\n","loss: 0.2140, acc: 0.9239\n","> val_acc: 0.7955, val_f1: 0.7881\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7955\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.1927, acc: 0.9375\n","loss: 0.1460, acc: 0.9323\n","loss: 0.1279, acc: 0.9460\n","loss: 0.1213, acc: 0.9492\n","loss: 0.1416, acc: 0.9435\n","loss: 0.1545, acc: 0.9375\n","loss: 0.1528, acc: 0.9365\n","> val_acc: 0.7727, val_f1: 0.7516\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.0933, acc: 0.9514\n","loss: 0.1033, acc: 0.9605\n","loss: 0.0947, acc: 0.9677\n","loss: 0.0902, acc: 0.9712\n","loss: 0.1006, acc: 0.9681\n","loss: 0.1001, acc: 0.9672\n","> val_acc: 0.8182, val_f1: 0.8232\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8182\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.0869, acc: 0.9583\n","loss: 0.0739, acc: 0.9727\n","loss: 0.0812, acc: 0.9688\n","loss: 0.0832, acc: 0.9688\n","loss: 0.0970, acc: 0.9647\n","loss: 0.1116, acc: 0.9621\n","> val_acc: 0.8295, val_f1: 0.8284\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8295\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.0594, acc: 0.9792\n","loss: 0.0660, acc: 0.9760\n","loss: 0.0515, acc: 0.9810\n","loss: 0.0552, acc: 0.9811\n","loss: 0.0595, acc: 0.9797\n","loss: 0.0604, acc: 0.9800\n","loss: 0.0717, acc: 0.9751\n","> val_acc: 0.8409, val_f1: 0.8357\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8409\n","<class 'torch.Tensor'>\n","tensor([0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 0, 0, 2, 1, 2, 1,\n","        1, 2, 1, 1, 1, 0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 0, 0, 1, 0, 2, 1, 1, 1, 2,\n","        0, 1, 1, 1, 0, 1, 1, 0, 2, 2, 2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 0, 2, 1, 0,\n","        0, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1, 0, 1, 2, 1, 0, 2, 1, 2, 2, 1, 2, 1, 0,\n","        2, 2, 1, 2, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 2, 2, 0, 1,\n","        2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 2, 0, 0, 2, 1, 1, 0, 1, 2, 0, 1, 0,\n","        2, 0, 2, 1, 0, 2])\n","0\n","0\n","1\n","1\n","1\n","0\n","0\n","2\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","2\n","2\n","2\n","0\n","0\n","2\n","1\n","2\n","1\n","1\n","2\n","1\n","1\n","1\n","0\n","0\n","2\n","2\n","2\n","1\n","2\n","1\n","1\n","2\n","0\n","0\n","1\n","0\n","2\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","2\n","2\n","1\n","0\n","2\n","0\n","1\n","2\n","1\n","2\n","0\n","0\n","2\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","2\n","0\n","1\n","0\n","1\n","2\n","1\n","0\n","2\n","1\n","2\n","2\n","1\n","2\n","1\n","0\n","2\n","2\n","1\n","2\n","2\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","2\n","2\n","2\n","2\n","0\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","2\n","2\n","1\n","0\n","1\n","2\n","2\n","0\n","0\n","2\n","1\n","1\n","0\n","1\n","2\n","0\n","1\n","0\n","2\n","0\n","2\n","1\n","0\n","2\n"]}]},{"cell_type":"code","source":["!python train.py --model_name bert_spc --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.20"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHXKEGwqAG1a","outputId":"413df6aa-743a-44c9-bddc-8fa9f06181c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f9e9ef1e3b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.2\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.2788, acc: 0.4062\n","loss: 1.1534, acc: 0.4437\n","loss: 1.0953, acc: 0.4854\n","loss: 1.0713, acc: 0.4969\n","loss: 1.0499, acc: 0.5050\n","> val_acc: 0.5787, val_f1: 0.5081\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.5787\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 0.7288, acc: 0.6875\n","loss: 0.8534, acc: 0.6364\n","loss: 0.8707, acc: 0.6339\n","loss: 0.8475, acc: 0.6452\n","loss: 0.8589, acc: 0.6280\n","loss: 0.8456, acc: 0.6397\n","> val_acc: 0.6298, val_f1: 0.5993\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6298\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.5393, acc: 0.7812\n","loss: 0.6569, acc: 0.7240\n","loss: 0.6764, acc: 0.7074\n","loss: 0.7186, acc: 0.6777\n","loss: 0.7065, acc: 0.6875\n","loss: 0.7353, acc: 0.6755\n","> val_acc: 0.6298, val_f1: 0.6370\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.5967, acc: 0.7500\n","loss: 0.6352, acc: 0.7548\n","loss: 0.6040, acc: 0.7554\n","loss: 0.5715, acc: 0.7595\n","loss: 0.5902, acc: 0.7485\n","loss: 0.5927, acc: 0.7465\n","> val_acc: 0.7064, val_f1: 0.7165\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7064\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.3507, acc: 0.8750\n","loss: 0.4495, acc: 0.8080\n","loss: 0.4159, acc: 0.8255\n","loss: 0.4302, acc: 0.8199\n","loss: 0.4400, acc: 0.8153\n","loss: 0.4191, acc: 0.8252\n","> val_acc: 0.6851, val_f1: 0.7101\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.2782, acc: 0.8875\n","loss: 0.2560, acc: 0.8917\n","loss: 0.2500, acc: 0.8975\n","loss: 0.2766, acc: 0.8875\n","loss: 0.2805, acc: 0.8847\n","loss: 0.2929, acc: 0.8784\n","> val_acc: 0.7574, val_f1: 0.7668\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7574\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.1402, acc: 0.9792\n","loss: 0.1963, acc: 0.9414\n","loss: 0.1733, acc: 0.9471\n","loss: 0.1732, acc: 0.9427\n","loss: 0.1828, acc: 0.9361\n","loss: 0.1853, acc: 0.9342\n","> val_acc: 0.8213, val_f1: 0.8107\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8213\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.1237, acc: 0.9554\n","loss: 0.1650, acc: 0.9449\n","loss: 0.1713, acc: 0.9444\n","loss: 0.1750, acc: 0.9426\n","loss: 0.1782, acc: 0.9375\n","loss: 0.1835, acc: 0.9353\n","> val_acc: 0.8468, val_f1: 0.8459\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8468\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.0731, acc: 0.9844\n","loss: 0.1069, acc: 0.9618\n","loss: 0.1384, acc: 0.9442\n","loss: 0.1482, acc: 0.9457\n","loss: 0.1567, acc: 0.9440\n","loss: 0.1632, acc: 0.9407\n","> val_acc: 0.8511, val_f1: 0.8470\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8511\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.0977, acc: 0.9653\n","loss: 0.0801, acc: 0.9770\n","loss: 0.0934, acc: 0.9720\n","loss: 0.1013, acc: 0.9663\n","loss: 0.1024, acc: 0.9643\n","loss: 0.1042, acc: 0.9650\n","> val_acc: 0.8000, val_f1: 0.8155\n","<class 'torch.Tensor'>\n","tensor([0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 0, 2, 1, 1, 1,\n","        1, 2, 1, 1, 1, 0, 0, 1, 2, 2, 1, 1, 0, 1, 2, 0, 0, 1, 0, 2, 1, 1, 1, 2,\n","        0, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 1, 0,\n","        0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 2, 1, 0, 1, 1, 2, 0, 1, 2, 1, 0,\n","        2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 1, 2, 0, 1,\n","        2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0,\n","        1, 0, 2, 1, 0, 1])\n","0\n","0\n","1\n","1\n","1\n","0\n","0\n","2\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","2\n","1\n","2\n","0\n","0\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","1\n","0\n","0\n","1\n","2\n","2\n","1\n","1\n","0\n","1\n","2\n","0\n","0\n","1\n","0\n","2\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","2\n","1\n","1\n","0\n","1\n","0\n","1\n","2\n","1\n","1\n","0\n","0\n","0\n","1\n","0\n","0\n","1\n","1\n","1\n","0\n","1\n","0\n","1\n","0\n","0\n","1\n","0\n","1\n","2\n","1\n","0\n","1\n","1\n","2\n","0\n","1\n","2\n","1\n","0\n","2\n","2\n","1\n","1\n","2\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","0\n","1\n","2\n","1\n","1\n","2\n","1\n","2\n","0\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","2\n","1\n","0\n","0\n","2\n","1\n","1\n","0\n","1\n","1\n","0\n","1\n","0\n","1\n","0\n","2\n","1\n","0\n","1\n"]}]},{"cell_type":"code","source":["!python train.py --model_name bert_spc --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.17"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WXm447fDxwK","outputId":"1eb7880b-dfa4-4ac2-cbee-99df80aa7ba6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f4ccc6183b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.17\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.2576, acc: 0.3750\n","loss: 1.1557, acc: 0.4375\n","loss: 1.1469, acc: 0.4208\n","loss: 1.1054, acc: 0.4375\n","loss: 1.0768, acc: 0.4575\n","loss: 1.0549, acc: 0.4677\n","> val_acc: 0.5500, val_f1: 0.5413\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.55\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 0.8512, acc: 0.5938\n","loss: 0.8553, acc: 0.5833\n","loss: 0.8367, acc: 0.6027\n","loss: 0.8023, acc: 0.6135\n","loss: 0.8082, acc: 0.6224\n","loss: 0.7968, acc: 0.6218\n","> val_acc: 0.5650, val_f1: 0.5576\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.565\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.7289, acc: 0.7188\n","loss: 0.6720, acc: 0.7383\n","loss: 0.6602, acc: 0.7356\n","loss: 0.6488, acc: 0.7378\n","loss: 0.6293, acc: 0.7378\n","loss: 0.6220, acc: 0.7411\n","> val_acc: 0.7150, val_f1: 0.6961\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.715\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.3894, acc: 0.7969\n","loss: 0.4627, acc: 0.8036\n","loss: 0.4308, acc: 0.8255\n","loss: 0.4037, acc: 0.8456\n","loss: 0.4133, acc: 0.8438\n","loss: 0.4194, acc: 0.8380\n","> val_acc: 0.7300, val_f1: 0.7338\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.73\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.3266, acc: 0.8750\n","loss: 0.3127, acc: 0.8906\n","loss: 0.2850, acc: 0.9034\n","loss: 0.2892, acc: 0.9062\n","loss: 0.2719, acc: 0.9048\n","loss: 0.2609, acc: 0.9099\n","loss: 0.2693, acc: 0.9030\n","> val_acc: 0.6700, val_f1: 0.6828\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.1711, acc: 0.9437\n","loss: 0.1913, acc: 0.9313\n","loss: 0.1893, acc: 0.9354\n","loss: 0.1878, acc: 0.9391\n","loss: 0.1871, acc: 0.9375\n","loss: 0.1930, acc: 0.9323\n","> val_acc: 0.7650, val_f1: 0.7381\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.765\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.2410, acc: 0.9062\n","loss: 0.1826, acc: 0.9340\n","loss: 0.1813, acc: 0.9308\n","loss: 0.1694, acc: 0.9342\n","loss: 0.1564, acc: 0.9375\n","loss: 0.1600, acc: 0.9343\n","> val_acc: 0.8100, val_f1: 0.7926\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.81\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.1429, acc: 0.9583\n","loss: 0.1136, acc: 0.9570\n","loss: 0.1004, acc: 0.9639\n","loss: 0.1031, acc: 0.9653\n","loss: 0.0967, acc: 0.9647\n","loss: 0.0959, acc: 0.9643\n","> val_acc: 0.8100, val_f1: 0.8069\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.0936, acc: 0.9531\n","loss: 0.0532, acc: 0.9821\n","loss: 0.0523, acc: 0.9844\n","loss: 0.0630, acc: 0.9835\n","loss: 0.0763, acc: 0.9773\n","loss: 0.0908, acc: 0.9734\n","> val_acc: 0.8150, val_f1: 0.7839\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.815\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.0986, acc: 0.9688\n","loss: 0.0573, acc: 0.9792\n","loss: 0.0584, acc: 0.9773\n","loss: 0.0527, acc: 0.9805\n","loss: 0.0497, acc: 0.9821\n","loss: 0.0528, acc: 0.9808\n","loss: 0.0579, acc: 0.9785\n","> val_acc: 0.7600, val_f1: 0.6923\n","<class 'torch.Tensor'>\n","tensor([0, 0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 0, 2, 1, 1, 1, 2,\n","        0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0,\n","        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 0, 1, 2, 1, 0,\n","        2, 2, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1,\n","        2, 1, 1, 1, 2, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 0,\n","        1, 0, 2, 1, 0, 1])\n","0\n","0\n","1\n","1\n","1\n","1\n","0\n","2\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","1\n","2\n","0\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","0\n","2\n","1\n","0\n","2\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","2\n","2\n","2\n","1\n","1\n","0\n","1\n","0\n","1\n","2\n","1\n","1\n","0\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","0\n","2\n","1\n","1\n","0\n","1\n","2\n","1\n","0\n","2\n","2\n","1\n","1\n","2\n","1\n","1\n","1\n","0\n","1\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","1\n","1\n","1\n","0\n","1\n","2\n","1\n","1\n","1\n","2\n","1\n","2\n","1\n","1\n","0\n","1\n","2\n","1\n","1\n","0\n","2\n","1\n","1\n","2\n","1\n","1\n","0\n","1\n","0\n","1\n","0\n","2\n","1\n","0\n","1\n"]}]},{"cell_type":"markdown","source":["### epochs"],"metadata":{"id":"-Xow5Hyd_7PE"}},{"cell_type":"code","source":["!python train.py --model_name bert_spc --dataset phase-1 --num_epoch 20 --device cuda:0 --polarities_dim 3  --valset_ratio 0.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QsCV1PQY_9hW","outputId":"160fe44b-e8cc-4fd8-b861-33ad2916252b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda memory allocated: 439075328\n","> n_trainable_params: 109484547, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fbcfcb8d3b0>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 20\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 768\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.1\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.1228, acc: 0.5437\n","loss: 1.0996, acc: 0.5312\n","loss: 1.0952, acc: 0.4854\n","loss: 1.0916, acc: 0.4656\n","loss: 1.0799, acc: 0.4525\n","loss: 1.0718, acc: 0.4552\n","> val_acc: 0.6154, val_f1: 0.5024\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6154\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 0.9997, acc: 0.4792\n","loss: 0.9662, acc: 0.5144\n","loss: 0.9419, acc: 0.5353\n","loss: 0.9264, acc: 0.5436\n","loss: 0.9129, acc: 0.5683\n","loss: 0.9055, acc: 0.5708\n","loss: 0.8906, acc: 0.5813\n","> val_acc: 0.6068, val_f1: 0.5881\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.6639, acc: 0.7083\n","loss: 0.7049, acc: 0.6836\n","loss: 0.7138, acc: 0.6683\n","loss: 0.7191, acc: 0.6684\n","loss: 0.7175, acc: 0.6603\n","loss: 0.6908, acc: 0.6797\n","loss: 0.6842, acc: 0.6866\n","> val_acc: 0.6752, val_f1: 0.6590\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6752\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.5032, acc: 0.8056\n","loss: 0.4969, acc: 0.8059\n","loss: 0.4930, acc: 0.8017\n","loss: 0.5020, acc: 0.7997\n","loss: 0.5025, acc: 0.8023\n","loss: 0.4861, acc: 0.8104\n","> val_acc: 0.6581, val_f1: 0.6408\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.3673, acc: 0.8750\n","loss: 0.3357, acc: 0.8646\n","loss: 0.3420, acc: 0.8494\n","loss: 0.3611, acc: 0.8457\n","loss: 0.3344, acc: 0.8586\n","loss: 0.3340, acc: 0.8606\n","loss: 0.3301, acc: 0.8639\n","> val_acc: 0.7094, val_f1: 0.7102\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7094\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.2053, acc: 0.9000\n","loss: 0.2086, acc: 0.9083\n","loss: 0.2097, acc: 0.9150\n","loss: 0.1928, acc: 0.9268\n","loss: 0.1887, acc: 0.9319\n","loss: 0.2305, acc: 0.9193\n","loss: 0.2271, acc: 0.9202\n","> val_acc: 0.7949, val_f1: 0.7961\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7949\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.1210, acc: 0.9375\n","loss: 0.1463, acc: 0.9375\n","loss: 0.1455, acc: 0.9442\n","loss: 0.1501, acc: 0.9375\n","loss: 0.1682, acc: 0.9323\n","loss: 0.1716, acc: 0.9321\n","> val_acc: 0.7949, val_f1: 0.7977\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.0304, acc: 1.0000\n","loss: 0.0618, acc: 0.9830\n","loss: 0.0753, acc: 0.9762\n","loss: 0.0841, acc: 0.9738\n","loss: 0.0960, acc: 0.9680\n","loss: 0.0938, acc: 0.9669\n","loss: 0.0900, acc: 0.9682\n","> val_acc: 0.8889, val_f1: 0.8834\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8889\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.0542, acc: 0.9844\n","loss: 0.0488, acc: 0.9866\n","loss: 0.0535, acc: 0.9844\n","loss: 0.0673, acc: 0.9761\n","loss: 0.0686, acc: 0.9773\n","loss: 0.0751, acc: 0.9734\n","loss: 0.0754, acc: 0.9756\n","> val_acc: 0.8889, val_f1: 0.8833\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.0139, acc: 1.0000\n","loss: 0.0613, acc: 0.9743\n","loss: 0.0469, acc: 0.9838\n","loss: 0.0476, acc: 0.9814\n","loss: 0.0571, acc: 0.9787\n","loss: 0.0573, acc: 0.9792\n","loss: 0.0631, acc: 0.9765\n","> val_acc: 0.9060, val_f1: 0.9021\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.906\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 10\n","loss: 0.0678, acc: 0.9625\n","loss: 0.0891, acc: 0.9594\n","loss: 0.0938, acc: 0.9625\n","loss: 0.0949, acc: 0.9625\n","loss: 0.0982, acc: 0.9613\n","loss: 0.1010, acc: 0.9604\n","> val_acc: 0.8205, val_f1: 0.7701\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 11\n","loss: 0.0297, acc: 1.0000\n","loss: 0.0661, acc: 0.9760\n","loss: 0.0667, acc: 0.9755\n","loss: 0.0620, acc: 0.9792\n","loss: 0.0508, acc: 0.9840\n","loss: 0.0492, acc: 0.9835\n","loss: 0.0563, acc: 0.9802\n","> val_acc: 0.8205, val_f1: 0.7929\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 12\n","loss: 0.0985, acc: 0.9583\n","loss: 0.0938, acc: 0.9570\n","loss: 0.0897, acc: 0.9639\n","loss: 0.0846, acc: 0.9670\n","loss: 0.0877, acc: 0.9660\n","loss: 0.0834, acc: 0.9665\n","loss: 0.0773, acc: 0.9697\n","> val_acc: 0.8205, val_f1: 0.8086\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 13\n","loss: 0.0158, acc: 1.0000\n","loss: 0.0202, acc: 0.9967\n","loss: 0.0175, acc: 0.9978\n","loss: 0.0245, acc: 0.9936\n","loss: 0.0231, acc: 0.9936\n","loss: 0.0327, acc: 0.9915\n","> val_acc: 0.8376, val_f1: 0.8306\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 14\n","loss: 0.0131, acc: 1.0000\n","loss: 0.0389, acc: 0.9896\n","loss: 0.0398, acc: 0.9858\n","loss: 0.0335, acc: 0.9902\n","loss: 0.0360, acc: 0.9866\n","loss: 0.0374, acc: 0.9880\n","loss: 0.0378, acc: 0.9879\n","> val_acc: 0.9060, val_f1: 0.8993\n",">> early stop.\n","<class 'torch.Tensor'>\n","tensor([0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 0, 1, 1, 2, 1,\n","        1, 2, 1, 1, 1, 0, 0, 1, 1, 2, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 2,\n","        0, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 1, 0, 2, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0,\n","        0, 1, 1, 1, 1, 2, 0, 1, 0, 0, 1, 0, 1, 2, 1, 0, 1, 1, 2, 0, 1, 2, 0, 0,\n","        2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 2, 2, 0, 1,\n","        2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0,\n","        1, 0, 2, 1, 0, 1])\n","0\n","0\n","1\n","1\n","1\n","0\n","0\n","2\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","2\n","1\n","2\n","0\n","0\n","1\n","1\n","2\n","1\n","1\n","2\n","1\n","1\n","1\n","0\n","0\n","1\n","1\n","2\n","1\n","0\n","1\n","1\n","2\n","0\n","0\n","1\n","0\n","0\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","2\n","1\n","1\n","0\n","2\n","0\n","1\n","2\n","1\n","1\n","0\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","2\n","0\n","1\n","0\n","0\n","1\n","0\n","1\n","2\n","1\n","0\n","1\n","1\n","2\n","0\n","1\n","2\n","0\n","0\n","2\n","2\n","1\n","1\n","2\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","1\n","2\n","2\n","0\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","0\n","1\n","2\n","1\n","0\n","0\n","2\n","1\n","1\n","0\n","1\n","1\n","0\n","1\n","0\n","1\n","0\n","2\n","1\n","0\n","1\n"]}]},{"cell_type":"markdown","source":["### use the large bert pretrained model"],"metadata":{"id":"mtdnw6jVGEfy"}},{"cell_type":"code","source":["!python train.py --model_name bert_spc --dataset phase-1 --num_epoch 10 --device cuda:0 --polarities_dim 3  --valset_ratio 0.15 --pretrained_bert_name bert-large-uncased --bert_dim 1024"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOWEiWYHGDzI","outputId":"da332d08-2257-4676-9853-32497ca92f81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda memory allocated: 1341395456\n","> n_trainable_params: 335144963, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7fbdaabf9440>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 10\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 1024\n",">>> pretrained_bert_name: bert-large-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.15\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.0761, acc: 0.5188\n","loss: 1.0236, acc: 0.5188\n","loss: 1.0132, acc: 0.5125\n","loss: 1.0022, acc: 0.5172\n","loss: 0.9850, acc: 0.5238\n","loss: 0.9880, acc: 0.5271\n","> val_acc: 0.5170, val_f1: 0.3250\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.517\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 0.9500, acc: 0.5357\n","loss: 0.8705, acc: 0.5846\n","loss: 0.8542, acc: 0.5903\n","loss: 0.8539, acc: 0.5980\n","loss: 0.8284, acc: 0.6170\n","loss: 0.8372, acc: 0.6107\n","> val_acc: 0.6136, val_f1: 0.4979\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.7175, acc: 0.6719\n","loss: 0.7295, acc: 0.6339\n","loss: 0.7251, acc: 0.6615\n","loss: 0.6894, acc: 0.6746\n","loss: 0.6922, acc: 0.6676\n","loss: 0.6986, acc: 0.6655\n","> val_acc: 0.6080, val_f1: 0.4897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.6948, acc: 0.6875\n","loss: 0.6678, acc: 0.6705\n","loss: 0.6295, acc: 0.6815\n","loss: 0.6516, acc: 0.6714\n","loss: 0.6425, acc: 0.6799\n","loss: 0.6342, acc: 0.6887\n","loss: 0.6245, acc: 0.6916\n","> val_acc: 0.6307, val_f1: 0.5113\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6307\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.5807, acc: 0.7188\n","loss: 0.5625, acc: 0.7188\n","loss: 0.5896, acc: 0.7210\n","loss: 0.5937, acc: 0.7270\n","loss: 0.5896, acc: 0.7266\n","loss: 0.5986, acc: 0.7112\n","> val_acc: 0.6250, val_f1: 0.5467\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.4902, acc: 0.7250\n","loss: 0.5264, acc: 0.7417\n","loss: 0.5319, acc: 0.7300\n","loss: 0.5295, acc: 0.7375\n","loss: 0.5422, acc: 0.7347\n","loss: 0.5429, acc: 0.7307\n","> val_acc: 0.6932, val_f1: 0.6628\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6932\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.4868, acc: 0.6875\n","loss: 0.4303, acc: 0.7917\n","loss: 0.4529, acc: 0.7585\n","loss: 0.4456, acc: 0.7656\n","loss: 0.4444, acc: 0.7664\n","loss: 0.4535, acc: 0.7680\n","loss: 0.4504, acc: 0.7621\n","> val_acc: 0.7557, val_f1: 0.7568\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7557\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.3352, acc: 0.8611\n","loss: 0.3713, acc: 0.8520\n","loss: 0.3445, acc: 0.8448\n","loss: 0.3396, acc: 0.8462\n","loss: 0.3492, acc: 0.8444\n","loss: 0.3480, acc: 0.8379\n","> val_acc: 0.8011, val_f1: 0.8070\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.2900, acc: 0.8854\n","loss: 0.2933, acc: 0.8750\n","loss: 0.2708, acc: 0.8846\n","loss: 0.2862, acc: 0.8785\n","loss: 0.2700, acc: 0.8845\n","loss: 0.2579, acc: 0.8906\n","> val_acc: 0.7670, val_f1: 0.7544\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.1169, acc: 0.9583\n","loss: 0.1830, acc: 0.9279\n","loss: 0.1928, acc: 0.9185\n","loss: 0.1844, acc: 0.9167\n","loss: 0.2049, acc: 0.9070\n","loss: 0.2008, acc: 0.9116\n","loss: 0.1980, acc: 0.9133\n","> val_acc: 0.8125, val_f1: 0.8146\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8125\n","<class 'torch.Tensor'>\n","tensor([0, 0, 1, 1, 1, 0, 0, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 0, 0, 2, 1, 1, 1,\n","        1, 2, 1, 1, 2, 0, 0, 2, 1, 2, 1, 2, 1, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 2,\n","        0, 1, 1, 1, 0, 1, 2, 0, 2, 2, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 0, 0, 1, 0,\n","        0, 1, 1, 1, 1, 2, 0, 1, 1, 0, 2, 0, 1, 2, 1, 0, 2, 1, 2, 0, 1, 1, 1, 0,\n","        2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 0, 2, 2, 2, 2, 0, 1,\n","        2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 2, 0, 1, 0,\n","        1, 0, 2, 0, 0, 1])\n","0\n","0\n","1\n","1\n","1\n","0\n","0\n","0\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","0\n","2\n","0\n","0\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","2\n","0\n","0\n","2\n","1\n","2\n","1\n","2\n","1\n","1\n","2\n","0\n","0\n","1\n","0\n","0\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","1\n","2\n","0\n","2\n","2\n","1\n","1\n","0\n","1\n","0\n","1\n","2\n","1\n","2\n","0\n","0\n","0\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","0\n","2\n","0\n","1\n","2\n","1\n","0\n","2\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","2\n","2\n","1\n","1\n","2\n","0\n","1\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","0\n","1\n","2\n","0\n","2\n","2\n","2\n","2\n","0\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","0\n","1\n","2\n","1\n","0\n","0\n","2\n","1\n","1\n","0\n","1\n","2\n","0\n","1\n","0\n","1\n","0\n","2\n","0\n","0\n","1\n"]}]},{"cell_type":"code","source":["!python train.py --model_name bert_spc --dataset phase-1 --num_epoch 20 --device cuda:0 --polarities_dim 3  --valset_ratio 0.15 --pretrained_bert_name bert-large-uncased --bert_dim 1024"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9tZWfpUgGr0I","outputId":"d3409bf6-a37d-44d4-ee06-ec2eefd6ebce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda memory allocated: 1341395456\n","> n_trainable_params: 335144963, n_nontrainable_params: 0\n","> training arguments:\n",">>> model_name: bert_spc\n",">>> dataset: phase-1\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7f945cd65440>\n",">>> lr: 2e-05\n",">>> dropout: 0.1\n",">>> l2reg: 0.01\n",">>> num_epoch: 20\n",">>> batch_size: 16\n",">>> log_step: 10\n",">>> embed_dim: 300\n",">>> hidden_dim: 300\n",">>> bert_dim: 1024\n",">>> pretrained_bert_name: bert-large-uncased\n",">>> max_seq_len: 85\n",">>> polarities_dim: 3\n",">>> hops: 3\n",">>> patience: 5\n",">>> device: cuda:0\n",">>> seed: 1234\n",">>> valset_ratio: 0.15\n",">>> local_context_focus: cdm\n",">>> SRD: 3\n",">>> model_class: <class 'models.bert_spc.BERT_SPC'>\n",">>> dataset_file: {'train': './datasets/train.raw', 'test': './datasets/test.raw'}\n",">>> inputs_cols: ['concat_bert_indices', 'concat_segments_indices']\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","loss: 1.0761, acc: 0.5188\n","loss: 1.0236, acc: 0.5188\n","loss: 1.0132, acc: 0.5125\n","loss: 1.0022, acc: 0.5172\n","loss: 0.9850, acc: 0.5238\n","loss: 0.9880, acc: 0.5271\n","> val_acc: 0.5170, val_f1: 0.3250\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.517\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 0.9500, acc: 0.5357\n","loss: 0.8705, acc: 0.5846\n","loss: 0.8542, acc: 0.5903\n","loss: 0.8539, acc: 0.5980\n","loss: 0.8284, acc: 0.6170\n","loss: 0.8372, acc: 0.6107\n","> val_acc: 0.6136, val_f1: 0.4979\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6136\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.7175, acc: 0.6719\n","loss: 0.7295, acc: 0.6339\n","loss: 0.7251, acc: 0.6615\n","loss: 0.6894, acc: 0.6746\n","loss: 0.6922, acc: 0.6676\n","loss: 0.6986, acc: 0.6655\n","> val_acc: 0.6080, val_f1: 0.4897\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.6948, acc: 0.6875\n","loss: 0.6678, acc: 0.6705\n","loss: 0.6295, acc: 0.6815\n","loss: 0.6516, acc: 0.6714\n","loss: 0.6425, acc: 0.6799\n","loss: 0.6342, acc: 0.6887\n","loss: 0.6245, acc: 0.6916\n","> val_acc: 0.6307, val_f1: 0.5113\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6307\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.5807, acc: 0.7188\n","loss: 0.5625, acc: 0.7188\n","loss: 0.5896, acc: 0.7210\n","loss: 0.5937, acc: 0.7270\n","loss: 0.5896, acc: 0.7266\n","loss: 0.5986, acc: 0.7112\n","> val_acc: 0.6250, val_f1: 0.5467\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.4902, acc: 0.7250\n","loss: 0.5264, acc: 0.7417\n","loss: 0.5319, acc: 0.7300\n","loss: 0.5295, acc: 0.7375\n","loss: 0.5422, acc: 0.7347\n","loss: 0.5429, acc: 0.7307\n","> val_acc: 0.6932, val_f1: 0.6628\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.6932\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.4868, acc: 0.6875\n","loss: 0.4303, acc: 0.7917\n","loss: 0.4529, acc: 0.7585\n","loss: 0.4456, acc: 0.7656\n","loss: 0.4444, acc: 0.7664\n","loss: 0.4535, acc: 0.7680\n","loss: 0.4504, acc: 0.7621\n","> val_acc: 0.7557, val_f1: 0.7568\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.7557\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.3352, acc: 0.8611\n","loss: 0.3713, acc: 0.8520\n","loss: 0.3445, acc: 0.8448\n","loss: 0.3396, acc: 0.8462\n","loss: 0.3492, acc: 0.8444\n","loss: 0.3480, acc: 0.8379\n","> val_acc: 0.8011, val_f1: 0.8070\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8011\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.2900, acc: 0.8854\n","loss: 0.2933, acc: 0.8750\n","loss: 0.2708, acc: 0.8846\n","loss: 0.2862, acc: 0.8785\n","loss: 0.2700, acc: 0.8845\n","loss: 0.2579, acc: 0.8906\n","> val_acc: 0.7670, val_f1: 0.7544\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.1169, acc: 0.9583\n","loss: 0.1830, acc: 0.9279\n","loss: 0.1928, acc: 0.9185\n","loss: 0.1844, acc: 0.9167\n","loss: 0.2049, acc: 0.9070\n","loss: 0.2008, acc: 0.9116\n","loss: 0.1980, acc: 0.9133\n","> val_acc: 0.8125, val_f1: 0.8146\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8125\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 10\n","loss: 0.0788, acc: 0.9812\n","loss: 0.1106, acc: 0.9688\n","loss: 0.1427, acc: 0.9563\n","loss: 0.1379, acc: 0.9531\n","loss: 0.1339, acc: 0.9550\n","loss: 0.1517, acc: 0.9510\n","> val_acc: 0.8466, val_f1: 0.8516\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8466\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 11\n","loss: 0.0999, acc: 0.9732\n","loss: 0.1138, acc: 0.9632\n","loss: 0.0943, acc: 0.9676\n","loss: 0.1106, acc: 0.9595\n","loss: 0.1229, acc: 0.9561\n","loss: 0.1272, acc: 0.9539\n","> val_acc: 0.8523, val_f1: 0.8531\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8523\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 12\n","loss: 0.0566, acc: 0.9688\n","loss: 0.0937, acc: 0.9598\n","loss: 0.1146, acc: 0.9505\n","loss: 0.1256, acc: 0.9485\n","loss: 0.1489, acc: 0.9446\n","loss: 0.1489, acc: 0.9433\n","> val_acc: 0.8807, val_f1: 0.8826\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.8807\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 13\n","loss: 0.0147, acc: 1.0000\n","loss: 0.0668, acc: 0.9659\n","loss: 0.0557, acc: 0.9762\n","loss: 0.0477, acc: 0.9819\n","loss: 0.0451, acc: 0.9848\n","loss: 0.0413, acc: 0.9853\n","loss: 0.0447, acc: 0.9836\n","> val_acc: 0.8580, val_f1: 0.8597\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 14\n","loss: 0.0885, acc: 0.9688\n","loss: 0.0753, acc: 0.9757\n","loss: 0.0659, acc: 0.9777\n","loss: 0.0677, acc: 0.9753\n","loss: 0.0776, acc: 0.9740\n","loss: 0.0774, acc: 0.9731\n","> val_acc: 0.8011, val_f1: 0.7764\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 15\n","loss: 0.0407, acc: 1.0000\n","loss: 0.0842, acc: 0.9792\n","loss: 0.0870, acc: 0.9800\n","loss: 0.0813, acc: 0.9804\n","loss: 0.0752, acc: 0.9778\n","loss: 0.0719, acc: 0.9773\n","> val_acc: 0.8523, val_f1: 0.8550\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 16\n","loss: 0.0547, acc: 0.9688\n","loss: 0.0855, acc: 0.9688\n","loss: 0.0629, acc: 0.9801\n","loss: 0.0587, acc: 0.9785\n","loss: 0.0579, acc: 0.9792\n","loss: 0.0606, acc: 0.9772\n","loss: 0.0607, acc: 0.9758\n","> val_acc: 0.8920, val_f1: 0.8933\n",">> saved: state_dict/bert_spc_phase-1_val_acc_0.892\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 17\n","loss: 0.0467, acc: 0.9792\n","loss: 0.0452, acc: 0.9836\n","loss: 0.0333, acc: 0.9892\n","loss: 0.0451, acc: 0.9856\n","loss: 0.0432, acc: 0.9847\n","loss: 0.0567, acc: 0.9799\n","> val_acc: 0.8864, val_f1: 0.8953\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 18\n","loss: 0.0552, acc: 0.9792\n","loss: 0.0683, acc: 0.9688\n","loss: 0.0486, acc: 0.9784\n","loss: 0.0403, acc: 0.9826\n","loss: 0.0490, acc: 0.9810\n","loss: 0.0438, acc: 0.9833\n","> val_acc: 0.8295, val_f1: 0.8133\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 19\n","loss: 0.0170, acc: 1.0000\n","loss: 0.0402, acc: 0.9856\n","loss: 0.0449, acc: 0.9837\n","loss: 0.0436, acc: 0.9848\n","loss: 0.0426, acc: 0.9840\n","loss: 0.0607, acc: 0.9811\n","loss: 0.0595, acc: 0.9821\n","> val_acc: 0.8864, val_f1: 0.8854\n","<class 'torch.Tensor'>\n","tensor([0, 0, 1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 0, 0, 2, 1, 1, 1,\n","        1, 1, 1, 1, 1, 0, 2, 2, 1, 2, 1, 2, 1, 1, 1, 0, 0, 1, 0, 2, 1, 1, 1, 2,\n","        0, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 2, 1, 2, 0, 0, 0, 1, 0,\n","        0, 1, 1, 1, 1, 2, 0, 1, 1, 0, 2, 0, 1, 2, 1, 1, 2, 1, 2, 0, 1, 1, 1, 0,\n","        2, 2, 1, 1, 2, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 2, 0, 2, 2, 2, 1, 0, 1,\n","        2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0,\n","        1, 0, 2, 1, 0, 1])\n","0\n","0\n","1\n","1\n","1\n","0\n","0\n","2\n","2\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","0\n","2\n","0\n","0\n","2\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","0\n","2\n","2\n","1\n","2\n","1\n","2\n","1\n","1\n","1\n","0\n","0\n","1\n","0\n","2\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","1\n","1\n","0\n","2\n","2\n","1\n","1\n","0\n","1\n","0\n","1\n","2\n","1\n","2\n","0\n","0\n","0\n","1\n","0\n","0\n","1\n","1\n","1\n","1\n","2\n","0\n","1\n","1\n","0\n","2\n","0\n","1\n","2\n","1\n","1\n","2\n","1\n","2\n","0\n","1\n","1\n","1\n","0\n","2\n","2\n","1\n","1\n","2\n","0\n","1\n","1\n","0\n","0\n","1\n","0\n","1\n","1\n","0\n","1\n","2\n","0\n","2\n","2\n","2\n","1\n","0\n","1\n","2\n","1\n","1\n","1\n","1\n","1\n","2\n","1\n","1\n","0\n","1\n","2\n","1\n","1\n","0\n","2\n","1\n","1\n","0\n","1\n","1\n","0\n","1\n","0\n","1\n","0\n","2\n","1\n","0\n","1\n"]}]}]}